{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White noise localization\n",
    "### Extension 2 : average the errors between the two mics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt \n",
    "import wave \n",
    "from scipy.io import wavfile\n",
    "import soundfile\n",
    "import time \n",
    "from scipy import signal\n",
    "import logging\n",
    "import datetime\n",
    "from itertools import combinations\n",
    "from Processing import calculate_angle_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extension2(J=1,runs=10,SNR=20,step=1,hrtf=0):\n",
    "    path_kemar = 'data/kemar_h_theta_1deg_time.npy' #  the path to the file\n",
    "    path_lego = 'data/lego1_h_theta_time.npy' #  path to lego mics data \n",
    "\n",
    "    if hrtf==0:\n",
    "        hrir = np.random.randn(160,180,6)\n",
    "    if hrtf==1:\n",
    "        hrir  = np.load(path_lego)\n",
    "    if hrtf==2:\n",
    "        hrir  = np.load(path_kemar) #head related transfer function\n",
    "        \n",
    "    T,D,M = hrir.shape\n",
    "\n",
    "    fs = 16000 #samples/second\n",
    "    T_ =0.5 #length of signal in time domain \n",
    "    N = int(T_*fs) #number of samples of the signal \n",
    "\n",
    "    mean = 0\n",
    "    std = 1 \n",
    "    num_samples = int(hrir.shape[0])\n",
    "    hrir_1 = np.zeros((160, 360))\n",
    "    hrir_2 = np.zeros((160, 360))\n",
    "    hrir_1 = hrir[:,:,0] \n",
    "    hrir_2 = hrir[:,:,1]\n",
    "    obs_len = N + int(hrir.shape[0]) -1  #length of the convolution\n",
    "\n",
    "    Df = int(hrir.shape[1]) #directions suppr\n",
    "\n",
    "\n",
    "    avg_err = 0\n",
    "    perfect = 0\n",
    "    start = time.time()\n",
    "    for rns in range(runs):\n",
    "        \n",
    "        St_all = np.zeros((N, J))\n",
    "        for j in range(J):\n",
    "            St_all[:, j] = np.random.normal(mean, std, size=N) #white noise\n",
    "\n",
    "        \n",
    "        theta = np.random.choice(range(Df), J, replace=False) #choose the directions randomly on the grid   \n",
    "\n",
    "    \n",
    "    \n",
    "        yt = np.zeros((obs_len, )) #recorded time domain signal  voir deuxième paramètre \n",
    "        yt2 = np.zeros((obs_len, ))\n",
    "\n",
    "    \n",
    "        for j in range(J):\n",
    "            yt += np.convolve(St_all[:, j], hrir_1[:, theta[j]]) #source signal convolved with corresponding directional response\n",
    "            yt2 += np.convolve(St_all[:, j], hrir_2[:, theta[j]])\n",
    "        \n",
    "        # Generate noise at required SNR    \n",
    "        sig_norm = np.linalg.norm(yt)\n",
    "        noise_t = np.random.randn(obs_len, ) #additive gaussian noise\n",
    "        noise_norm = sig_norm/(10.**(SNR/20.))\n",
    "        noise_t = noise_norm*noise_t/np.linalg.norm(noise_t)\n",
    "\n",
    "        yt += noise_t #noisy signal\n",
    "    \n",
    "        # noise for second mic\n",
    "        sig_norm = np.linalg.norm(yt)\n",
    "        noise_t = np.random.randn(obs_len, ) #additive gaussian noise\n",
    "        noise_norm = sig_norm/(10.**(SNR/20.))\n",
    "        noise_t = noise_norm*noise_t/np.linalg.norm(noise_t)\n",
    "\n",
    "        yt2 += noise_t #noisy signal\n",
    "    \n",
    "    \n",
    "    \n",
    "        f, t, y = signal.stft(yt, fs=1.0, window='hann', nperseg=160)\n",
    "        f, t, y2 = signal.stft(yt2, fs=1.0, window='hann', nperseg=160)\n",
    "    \n",
    "        N_ = y.shape[1] #number of frames\n",
    "\n",
    "        y_mean = np.mean(np.abs(y)**2, axis=1) #mean power frame\n",
    "        y_mean = y_mean/np.linalg.norm(y_mean) #normalize the observation\n",
    "    \n",
    "        y_mean2 = np.mean(np.abs(y2)**2, axis=1) #mean power frame\n",
    "        y_mean2 = y_mean2/np.linalg.norm(y_mean2) #normalize the observation\n",
    "\n",
    "        H1 = np.fft.rfft(hrir_1,axis=0)\n",
    "        H_coarse1 = H1[:,::step]\n",
    "    \n",
    "        H2 = np.fft.rfft(hrir_2,axis=0)\n",
    "        H_coarse2 = H2[:,::step]\n",
    "    \n",
    "        anglesf = np.arange(Df, dtype=np.int64)*360./Df # list of angles in degrees\n",
    "        # Initialize variables\n",
    "    \n",
    "        D = H_coarse1.shape[1]\n",
    "    \n",
    "        best_ind = np.inf #index corresponding to best direction tuple\n",
    "        smallest_norm = np.inf #smallest projection error\n",
    "        best_dir = theta #best direction tuple\n",
    "        \n",
    "        # Search all combinations\n",
    "        pairs2 = combinations(range(D), J) #all combinations in range(D) and length J=2\n",
    "    \n",
    "    \n",
    "        for q2, d2 in enumerate(pairs2): \n",
    "            Bj1 = np.abs(H_coarse1[:, d2])**2 #vectors in current guess contains the two vectors \n",
    "            Pj1 = Bj1.dot(np.linalg.pinv(Bj1)) #projection matrix\n",
    "            proj_error1 = np.linalg.norm((np.eye(int(y.shape[0])) - Pj1).dot(y_mean)) #projection error1\n",
    "            \n",
    "            Bj2 = np.abs(H_coarse2[:, d2])**2 #vectors in current guess contains the two vectors \n",
    "            Pj2 = Bj2.dot(np.linalg.pinv(Bj2)) #projection matrix\n",
    "            proj_error2 = np.linalg.norm((np.eye(int(y.shape[0])) - Pj2).dot(y_mean2)) #projection error2\n",
    "            \n",
    "            proj_error = (proj_error1 + proj_error2)/2\n",
    "        \n",
    "            if proj_error <= smallest_norm:\n",
    "                smallest_norm = proj_error\n",
    "                best_ind = q2\n",
    "                best_dir = d2\n",
    "    \n",
    "        theta_hat = step*np.array(best_dir) #map coarse index to fine index\n",
    "        min_err, best_perm = calculate_angle_error(theta, theta_hat, anglesf) #calculate error between chosen and true directions        \n",
    "        #min_err, best_perm = calculate_angle_error(np.round(theta,-1), theta_hat, anglesf)     \n",
    "        if min_err==0:\n",
    "            perfect+=1\n",
    "        \n",
    "        end = time.time() - start\n",
    "        avg_err += min_err \n",
    "        print('iteration ' + str(rns+1) +' error : '+ str(min_err) + '  ground truth : ' + str(theta)+ '  estimation : ' + str(best_perm) )\n",
    "\n",
    "    avg_err = avg_err/runs\n",
    "    print(str(J) +' sources')\n",
    "    print('average error : ' + str(avg_err) +' over ' + str(runs) + ' runs')\n",
    "    accuracy = (perfect/runs)*100\n",
    "    print('accuracy : ' + str(accuracy) + ' %')\n",
    "    \n",
    "    return avg_err,accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the function extension 2 \n",
    "we fix the parameters : \n",
    "\n",
    "J : number of sources to detect   \n",
    "runs : number of runs over which we calculate the average error   \n",
    "SNR : signal to noise ration  \n",
    "hrtf : to choose Lego, Kemar, or random data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 100\n",
    "# example with 2 sources on 100 runs and lego data\n",
    "avg_err, accuracy = extension2(J=2,runs=runs,SNR=20,step=1, hrtf=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
