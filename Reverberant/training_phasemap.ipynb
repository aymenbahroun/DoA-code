{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase maps \n",
    "#### The inputs to train the CNN model\n",
    "Each of size 129x6 (frequency bins x number of microphones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed = 0.00%\n",
      "data processed = 7.44%\n",
      "data processed = 14.88%\n",
      "data processed = 22.32%\n",
      "data processed = 29.76%\n",
      "data processed = 37.20%\n",
      "data processed = 44.64%\n",
      "data processed = 52.08%\n",
      "data processed = 59.52%\n",
      "data processed = 66.96%\n",
      "data processed = 74.40%\n",
      "data processed = 81.85%\n",
      "data processed = 89.29%\n",
      "data processed = 96.73%\n",
      "finished processing\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "    part1 : Convolution of the train rir data with noise\n",
    "            Phase of STFT of the signal\n",
    "'''\n",
    "\n",
    "#load the data \n",
    "train_data = np.load('../train_loader2.npy')\n",
    "\n",
    "\n",
    "fs = 8000      #samples/second\n",
    "T_ = 6          #length of signal in time domain \n",
    "N = int(T_*fs) #number of samples of the signal \n",
    "\n",
    "mean = 0\n",
    "std = 1 \n",
    "\n",
    "white_noise = np.random.normal(mean, std, size=N) #white noise\n",
    "obs_len = N + train_data.shape[1] -1  #length of the convolution\n",
    "\n",
    "processed = np.zeros((train_data.shape[0],129,406)) # (129,406) size of STFT\n",
    "\n",
    "\n",
    "\n",
    "for j in range(train_data.shape[0]):\n",
    "    yt = np.zeros((obs_len, )) \n",
    "    yt += np.convolve(white_noise, train_data[j,:])\n",
    "    \n",
    "    # Generate additive gaussian noise at SNR between 10 and 20   \n",
    "\n",
    "    SNR = np.random.randint(10,21)\n",
    "    sig_norm = np.linalg.norm(yt)\n",
    "    noise_t = np.random.randn(obs_len, ) #additive gaussian noise\n",
    "    noise_norm = sig_norm/(10.**(SNR/20.))\n",
    "    noise_t = noise_norm*noise_t/np.linalg.norm(noise_t)\n",
    "    \n",
    "    yt += noise_t #noisy signal\n",
    "\n",
    "    f, t, Zxx = signal.stft(yt, fs, nperseg=256)\n",
    "    # store the phase of the processed STFT\n",
    "    processed[j,:,:] = np.angle(Zxx)\n",
    "    if(j%100==0):\n",
    "        percentage = (j/train_data.shape[0])*100\n",
    "        print('data processed = {:0.2f}%'.format(percentage))\n",
    "        \n",
    "print('finished processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of 1st data reshaped = 0.00%\n",
      "percentage of 1st data reshaped = 4.46%\n",
      "percentage of 1st data reshaped = 8.93%\n",
      "percentage of 1st data reshaped = 13.39%\n",
      "percentage of 1st data reshaped = 17.86%\n",
      "percentage of 1st data reshaped = 22.32%\n",
      "percentage of 1st data reshaped = 26.79%\n",
      "percentage of 1st data reshaped = 31.25%\n",
      "percentage of 1st data reshaped = 35.71%\n",
      "percentage of 1st data reshaped = 40.18%\n",
      "percentage of 1st data reshaped = 44.64%\n",
      "percentage of 1st data reshaped = 49.11%\n",
      "percentage of 1st data reshaped = 53.57%\n",
      "percentage of 1st data reshaped = 58.04%\n",
      "percentage of 1st data reshaped = 62.50%\n",
      "percentage of 1st data reshaped = 66.96%\n",
      "percentage of 1st data reshaped = 71.43%\n",
      "percentage of 1st data reshaped = 75.89%\n",
      "percentage of 1st data reshaped = 80.36%\n",
      "percentage of 1st data reshaped = 84.82%\n",
      "percentage of 1st data reshaped = 89.29%\n",
      "percentage of 1st data reshaped = 93.75%\n",
      "percentage of 1st data reshaped = 98.21%\n",
      "Finished 1st reshaping\n",
      "percentage of 2nd data reshaped = 0.00%\n",
      "percentage of 2nd data reshaped = 4.46%\n",
      "percentage of 2nd data reshaped = 8.93%\n",
      "percentage of 2nd data reshaped = 13.39%\n",
      "percentage of 2nd data reshaped = 17.86%\n",
      "percentage of 2nd data reshaped = 22.32%\n",
      "percentage of 2nd data reshaped = 26.79%\n",
      "percentage of 2nd data reshaped = 31.25%\n",
      "percentage of 2nd data reshaped = 35.71%\n",
      "percentage of 2nd data reshaped = 40.18%\n",
      "percentage of 2nd data reshaped = 44.64%\n",
      "percentage of 2nd data reshaped = 49.11%\n",
      "percentage of 2nd data reshaped = 53.57%\n",
      "percentage of 2nd data reshaped = 58.04%\n",
      "percentage of 2nd data reshaped = 62.50%\n",
      "percentage of 2nd data reshaped = 66.96%\n",
      "percentage of 2nd data reshaped = 71.43%\n",
      "percentage of 2nd data reshaped = 75.89%\n",
      "percentage of 2nd data reshaped = 80.36%\n",
      "percentage of 2nd data reshaped = 84.82%\n",
      "percentage of 2nd data reshaped = 89.29%\n",
      "percentage of 2nd data reshaped = 93.75%\n",
      "percentage of 2nd data reshaped = 98.21%\n",
      "Finished 2nd reshaping\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Part2 : reshaping the data structure for training the model\n",
    "'''\n",
    "\n",
    "n_mics = 6\n",
    "size1 = int(processed.shape[0]/n_mics)\n",
    "x2 = np.zeros((size1,129,6,406))\n",
    "for i in range(size1):\n",
    "\n",
    "    mic0 = processed[6*i + 0,:,:]\n",
    "    mic1 = processed[6*i + 1,:,:]\n",
    "    mic2 = processed[6*i + 2,:,:]\n",
    "    mic3 = processed[6*i + 3,:,:]\n",
    "    mic4 = processed[6*i + 4,:,:]\n",
    "    mic5 = processed[6*i + 5,:,:]\n",
    "    x = np.zeros((129,6,1))\n",
    "    for j in range(406):\n",
    "        x0 = np.vstack((mic0[:,j],mic1[:,j],mic2[:,j],mic3[:,j],mic4[:,j], mic5[:,j])).T\n",
    "        x = np.concatenate((x,x0[:,:,None]),axis=2)\n",
    "    \n",
    "    x = x[:,:,1:x.shape[2]]\n",
    "    x2 [i,:,:,:]= x\n",
    "    if(i%10==0):\n",
    "        percentage = (i/size1)*100\n",
    "        print('percentage of 1st data reshaped = {:0.2f}%'.format(percentage))\n",
    "print('Finished 1st reshaping')   \n",
    "size2 = int(x2.shape[0]*x2.shape[3])\n",
    "\n",
    "\n",
    "x3 = np.zeros((size2,129,n_mics))\n",
    "\n",
    "for i in range(size1):\n",
    "    for j in range(406):\n",
    "        x3[406*i+j,:,:] = x2[i,:,:,j] \n",
    "    if(i%10==0):\n",
    "        percentage = (i/size1)*100\n",
    "        print('percentage of 2nd data reshaped = {:0.2f}%'.format(percentage))\n",
    "print('Finished 2nd reshaping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 class here because we worked with the train_loader_8class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_data_8class', x3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
