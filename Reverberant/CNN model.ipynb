{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN \n",
    "### convolutional neurol network for 8 class classification \n",
    "To have a 15 or a 30 classifier, we modifie the final fully connected layer     \n",
    "self.fc3 = nn.Linear(512, 8)  : 8 class classifier   \n",
    "self.fc3 = nn.Linear(512, 15) : 15 class classifier   \n",
    "self.fc3 = nn.Linear(512, 30) : 30 class classifier   \n",
    "\n",
    "*And of course the training and testing data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input phase map channel, 64 output channels, 2x2 square convolution\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        #(M-3)x(K-3) with M = 6mics and K = 129frequ bins for each time frame TF\n",
    "        # --> M-3 = 3 and K-3 = 126\n",
    "        self.fc1 = nn.Linear(64 * 3 * 126, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        #with resolution of 45Â° so number of classes is I=8\n",
    "        self.fc3 = nn.Linear(512, 8) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)  #No need activation since CrossEntropyLoss makes the Softmax\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(Dataset):\n",
    "    \n",
    "    #Initialize data, download, etc.\n",
    "    def __init__(self):\n",
    "        x = np.load('train_data_8class.npy')\n",
    "        x = np.reshape(x, (x.shape[0],1,x.shape[1],x.shape[2]))\n",
    "        y = np.load('train_labels_8class.npy')\n",
    "        y.astype(int)\n",
    "        self.len = y.shape[0]\n",
    "        x = torch.from_numpy(x)\n",
    "        y = torch.from_numpy(y)\n",
    "        self.x_data = x.double()\n",
    "        self.y_data = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Train()\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=512,\n",
    "                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(Dataset):\n",
    "    \n",
    "    #Initialize data, download, etc.\n",
    "    def __init__(self):\n",
    "        x = np.load('test_data_8class_speech.npy')\n",
    "        x = np.reshape(x, (x.shape[0],1,x.shape[1],x.shape[2]))\n",
    "        y = np.load('test_labels_8class.npy')\n",
    "        y.astype(int)\n",
    "        self.len = y.shape[0]\n",
    "        x = torch.from_numpy(x)\n",
    "        y = torch.from_numpy(y)\n",
    "        self.x_data = x.double()\n",
    "        self.y_data = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = Test()\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=512,\n",
    "                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters for training the model\n",
    "1 epoch because of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_epoch = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.double()\n",
    "for epoch in range(num_epoch):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        #wrap them in variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        #forward pass : compute predicted y by passing x to the model\n",
    "        y_pred = model(inputs)\n",
    "        \n",
    "        #compute and print loss \n",
    "        loss = criterion(y_pred, labels)\n",
    "        \n",
    "        #print(epoch, i, loss.data[0])\n",
    "        print(epoch, i, loss.data.item())\n",
    "        \n",
    "        #zero gradients, performs a backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model \n",
    "Calculation of the accuracy of the model on the test set (test phase maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracy of the trained model on the testing data \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(total)\n",
    "\n",
    "print('Accuracy of the network on the test phase maps: {:0.2f} %' .format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
